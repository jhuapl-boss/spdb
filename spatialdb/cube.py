# Copyright 2014 NeuroData (http://neurodata.io)
# Copyright 2016 The Johns Hopkins University Applied Physics Laboratory
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import numpy as np
import blosc
from PIL import Image

from abc import ABCMeta, abstractmethod

import spdb.c_lib.ndtype as ndtype
from spdb.c_lib import ndlib

from .error import SpdbError, ErrorCode

"""
.. module:: Cube
    :synopsis: Manipulate the in-memory data representation of the 3-D cube of data that contains image or annotations.
"""


class Cube(metaclass=ABCMeta):
    """An abstract base class to store 3D matrix data with time-series support and perform common operations

    The create_cube method is a factory method that will return the proper Cube child class instance based on the
    provided resource instance

    Args:
      cube_size list(int): Dimensions of the matrix in [x, y, z]
      time_range list(int): The contiguous range of time samples stored in this cube instance

    Attributes:
      cube_size list(int):  Dimensions of the matrix in [x, y, z]
      time_samples list(int): The min and max time samples store in cube, in python convention (start inclusive, stop
      exclusive)
      is_time_series bool: A flag indicating if the cube contains a time-series or single time sample
      z_dim (int): The Z dimension of the data matrix
      y_dim (int): The Y dimension of the data matrix
      x_dim (int): The X dimension of the data matrix
      data (numpy.ndarray): The 3D matrix of data as a numpy array in [t, z, y, x]
      _created_from_zeros (bool): Flag indicates if the data was generated by this instance or pre-existing
    """
    def __init__(self, cube_size, time_range=None):
        # cube_size is represented in x,y,z but data is stored c-ordered internally as z,y,x
        # cube_size is in z,y,x for interactions with tile/image data
        # time_range specified with time points stored in this cube instance
        self.z_dim, self.y_dim, self.x_dim = self.cube_size = [cube_size[2], cube_size[1], cube_size[0]]

        # _created_from_zeros flag indicates if the data was generated by this instance or pre-existing
        self._created_from_zeros = False

        self.data = None

        # Setup time sample properties
        if time_range:
            self.is_time_series = True
            self.time_range = time_range
        else:
            self.is_time_series = False
            self.time_range = [0, 1]

    def add_data(self, input_cube, index):
        """Add data to a larger cube (this instance) from a smaller cube (input_cube)

        Args:
            input_cube (spdb.cube.Cube): Input Cube instance from which to merge data
            index: relative morton ID indicating where to insert the data

        Returns:
            None
        """
        x_offset = index[0] * input_cube.x_dim
        y_offset = index[1] * input_cube.y_dim
        z_offset = index[2] * input_cube.z_dim

        np.copyto(self.data[input_cube.time_range[0]:input_cube.time_range[1],
                            z_offset:z_offset + input_cube.z_dim,
                            y_offset:y_offset + input_cube.y_dim,
                            x_offset:x_offset + input_cube.x_dim], input_cube.data[:, :, :, :])

    def trim(self, x_offset, x_size, y_offset, y_size, z_offset, z_size):
        """Trim off excess data if not cuboid aligned. Applies to ALL time samples

        Args:
            x_offset (int): Start X index of data to keep
            x_size (int): X extent of data to keep
            y_offset (int): Start Y index of data to keep
            y_size (int): Y extent of data to keep
            z_offset (int): Start Z index of data to keep
            z_size (int): Y extent of data to keep

        Returns:
            None
        """
        self.data = self.data[:, z_offset:z_offset + z_size, y_offset:y_offset + y_size, x_offset:x_offset + x_size]

        # update the cube dimensions, ignoring the time component since it does not change
        self.z_dim, self.y_dim, self.x_dim = self.cube_size = list(self.data.shape[1:])

    def to_blosc_numpy(self):
        """A generator that packs each time point of data in this Cube instance using Blosc
        and the numpy array specific interface.

        Returns:
            (int, bytes) - a tuple of the time sample and the compressed, serialized byte array of Cube matrix data

        """
        # Create compressed byte arrays for each time point, and return in order as a tuple, indicating
        # the time point
        for cnt, t in enumerate(range(self.time_range[0], self.time_range[1])):
            yield (t, blosc.pack_array(self.data[cnt, :, :, :]))

    def from_blosc_numpy(self, byte_arrays, time_sample_range=None):
        """Uncompress and populate Cube data from a Blosc serialized and compressed byte array using the numpy interface

        Assume data is stored in cube in tzyx ordering and each byte array should be zyx ordered.

        Args:
            byte_arrays list[str]:  list of time ordered, compressed, serialized byte array of Cube matrix data
            time_sample_range list(int): The min and max time samples that input_data represents in python convention
            (start inclusive, stop exclusive)

        Returns:
            None

        """
        try:
            if not time_sample_range:
                # This isn't a time-series cube, so use default
                self.is_time_series = False
                self.time_range = time_sample_range = [0, 1]
            else:
                self.is_time_series = True
                self.time_range = time_sample_range

            # Unpack all of the arrays into the cube
            for idx, t in enumerate(range(time_sample_range[0], time_sample_range[1])):
                self.data[idx, :, :, :] = blosc.unpack_array(byte_arrays[idx])

            # Set shape
            self.z_dim, self.y_dim, self.x_dim = self.cube_size = list(self.data.shape[1:])

        except:
            raise SpdbError("IO Error", "Failed to decompress database cube.  Data integrity concern.",
                            ErrorCode.IO_ERROR)

        self._created_from_zeros = False

    def overwrite(self, input_data, time_sample_range=None):
        """ Overwrite data with all non-zero values in the input_data

        Function is accelerated for annotation overwrite operations since you often are merging
        two sparse cubes.  If not uint32 or uint64 this just performs a copy.

        If time_sample_range is provided, data will be inserted at the appropriate time sample

        Args:
            input_data (numpy.ndarray): Input data matrix to overwrite the current Cube data
            time_sample_range list(int): The min and max time samples that input_data represents in python convention
            (start inclusive, stop exclusive)

        Returns:
            None

        """
        if self.data.dtype != input_data.dtype:
            raise SpdbError("IO Error", "Conflicting data types for overwrite.",
                            ErrorCode.IO_ERROR)

        if not time_sample_range:
            # If no time sample range provided use default of 0
            time_sample_range = [0, 1]

        if self.data.dtype == np.uint32 or self.data.dtype == np.uint64:
            for cnt, t in enumerate(range(time_sample_range)):
                # TODO: look into accelerating time-series overwrites
                # Currently not optimized to overwrite all time samples at once so do one at a time
                self.data[t, :, :, :] = ndlib.overwriteDense_ctype(self.data[t, :, :, :], input_data[cnt, :, :, :])
        else:
            self.data[time_sample_range[0]:time_sample_range[1], :, :, :] = input_data[:, :, :, :]

    def is_not_zeros(self):
        """Check if the data matrix is all zeros

        Returns:
            bool
        """
        return np.any(self.data)

    def from_zeros(self):
        """Determine if the Cube instance was created from all zeros

        Returns:
            bool
        """
        return self._created_from_zeros

    @abstractmethod
    def zeros(self):
        """Initialize Cube instance to all zeros. Must override in child classes to properly deal with datatype and
        other unique properties.

        Example for uin8 based cube:
            self._created_from_zeros = True
            self.data = np.zeros(self.cube_size, dtype=np.uint8)

        Returns:
            None
        """
        return NotImplemented

    @abstractmethod
    def xy_image(self, z_index=0):
        """Render an image in the XY plane. Mut be overridden in child class to deal with data types and shape

        Example for uin8 based cube:
            zdim, ydim, xdim = self.data.shape
            return Image.frombuffer('L', (xdim, ydim), self.data[z_index, :, :].flatten(), 'raw', 'L', 0, 1)

        Args:
            z_index: Optional Z index into the data matrix from which to render the image.

        Returns:
            Image
        """
        return NotImplemented

    @abstractmethod
    def xz_image(self, z_scale=1, y_index=0):
        """Render an image in the xz plane. Mut be overridden in child class to deal with data types and shape

        Example for uin8 based cube:
            zdim, ydim, xdim = self.data.shape
            out_image = Image.frombuffer('L', (xdim, zdim), self.data[:, y_index, :].flatten(), 'raw', 'L', 0, 1)
            return out_image.resize([xdim, int(zdim*z_scale)])

        Args:
            z_scale: Scaling factor for the z-dimension. Useful for rendering non-isotropic data
            y_index: Optional Y index into the data matrix from which to render the image.

        Returns:
            Image
        """
        return NotImplemented

    @abstractmethod
    def yz_image(self, z_scale=1, x_index=0):
        """Render an image in the yz plane. Mut be overridden in child class to deal with data types and shape

        Example for uin8 based cube:
            zdim, ydim, xdim = self.data.shape
            out_image = Image.frombuffer('L', (ydim, zdim), self.data[:, :, 0].flatten(), 'raw', 'L', 0, 1)
            return out_image.resize([ydim, int(zdim*z_scale)])

        Args:
            z_scale: Scaling factor for the z-dimension. Useful for rendering non-isotropic data
            x_index: Optional X index into the data matrix from which to render the image.

        Returns:
            Image
        """
        return NotImplemented

    @staticmethod
    def create_cube(resource, cube_size, time_range=None):
        """Static factory method that creates the proper child class instance type based on the resource being accessed

        Args:
            resource (project.BossResource): Data model info based on the request or target resource
            cube_size ([int, int int]): Dimensions of the matrix in [x, y, z]
            time_range list(int): The contiguous range of time samples stored in this cube instance

        Returns:
            cube.Cube - Instance of a child class of Cube
        """
        data_type = resource.get_data_type()

        # 32-Bit layer is an Annotation Cube
        if not resource.is_channel() and data_type in ndtype.DTYPE_uint32:
            # return anncube.AnnotateCube32(cube_size)
            raise SpdbError("Proposed Capability", "Data type not yet supported",
                            ErrorCode.FUTURE)
        elif not resource.is_channel() and data_type in ndtype.DTYPE_uint64:
            # return anncube.AnnotateCube64(cube_size)
            raise SpdbError("Proposed Capability", "Data type not yet supported",
                            ErrorCode.FUTURE)
        # Assume channels here
        elif data_type in ndtype.DTYPE_uint8:
            from .imagecube import ImageCube8
            return ImageCube8(cube_size, time_range)
        elif data_type in ndtype.DTYPE_uint16:
            from .imagecube import ImageCube16
            return ImageCube16(cube_size, time_range)
        else:
            return Cube(cube_size, time_range)


# end cube

# These need to be at the bottom because of the factory method
# from spdb import  anncube
# from spdb import timecube
